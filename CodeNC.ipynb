{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLy2puniLNog"
      },
      "source": [
        "###Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHu5kiPEAV-p"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import pairwise_distances\n",
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import accuracy_score, adjusted_rand_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "# Skimage\n",
        "from skimage.feature import hog, local_binary_pattern\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans,DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, adjusted_rand_score\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeBDAWlULxWq"
      },
      "source": [
        "###Global Variables (Parameters for feature extraction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDYgMACKC9E9"
      },
      "outputs": [],
      "source": [
        "SEED = 782\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "DATA_DIR = \"imagenet\"\n",
        "TEST_SPLIT = 0.2\n",
        "VAL_SPLIT = 0.2\n",
        "\n",
        "# Classical SIFT config\n",
        "MAX_DESCRIPTORS = 30_000_000\n",
        "K_SIFT = 512   # codebook size\n",
        "SIFT_WEIGHT = 2.0\n",
        "\n",
        "# HOG config\n",
        "HOG_ORIENTATIONS = 9\n",
        "HOG_PIXELS_PER_CELL = (8, 8)\n",
        "HOG_CELLS_PER_BLOCK = (2, 2)\n",
        "HOG_DIM = 512\n",
        "HOG_WEIGHT = 1.0\n",
        "\n",
        "# Color Hist config\n",
        "COLOR_BINS_PER_CHANNEL = 43  # => 129D\n",
        "COLOR_WEIGHT = 1.0\n",
        "\n",
        "# Canny config\n",
        "CANNY_THRESHOLD1 = 100\n",
        "CANNY_THRESHOLD2 = 200\n",
        "CANNY_GRID = (8, 8)  # => 64D\n",
        "CANNY_WEIGHT = 1.0\n",
        "\n",
        "# LBP config\n",
        "LBP_RADIUS = 1\n",
        "LBP_POINTS = 8  # => histogram dimension = 10\n",
        "LBP_WEIGHT = 1.0\n",
        "\n",
        "# K-Means classifier\n",
        "KMEANS_CLUSTERS = 90  # usually matches #classes\n",
        "\n",
        "# Deep Feature Extraction config\n",
        "BATCH_SIZE_DEEP = 32\n",
        "NUM_WORKERS_DEEP = 0  # or > 0 for speed if your CPU can handle\n",
        "DEVICE = 'cpu'        # or 'cuda' if you have a GPU\n",
        "\n",
        "# Scaling & PCA\n",
        "APPLY_SCALING = True\n",
        "APPLY_PCA = True\n",
        "PCA_N_COMPONENTS = 2700\n",
        "\n",
        "#Storage\n",
        "REUSE_classical = True\n",
        "REUSE_deep = True\n",
        "REUSE_text = True\n",
        "\n",
        "# Text (BLIP + SBERT) configs\n",
        "BATCH_SIZE_TEXT = 8\n",
        "NUM_WORKERS_TEXT = 0\n",
        "BLIP_MODEL_NAME = \"Salesforce/blip-image-captioning-base\"\n",
        "SBERT_MODEL_NAME = \"all-mpnet-base-v2\"\n",
        "MAX_NEW_TOKENS = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENVi9L2HLysV"
      },
      "source": [
        "###Basic Data Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGmMHVRoDBW7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_dataset_paths(root_dir):\n",
        "    \"\"\"\n",
        "    Loads images from subfolders of root_dir. Each subfolder is a different class.\n",
        "    Returns:\n",
        "      (image_paths, labels, class_names)\n",
        "    \"\"\"\n",
        "    class_names = sorted([\n",
        "        d for d in os.listdir(root_dir)\n",
        "        if os.path.isdir(os.path.join(root_dir, d))\n",
        "    ])\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    for label_idx, cname in enumerate(class_names):\n",
        "        class_dir = os.path.join(root_dir, cname)\n",
        "        exts = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.JPEG\")\n",
        "        files = []\n",
        "        for ext in exts:\n",
        "            files.extend(glob(os.path.join(class_dir, ext)))\n",
        "        for f in files:\n",
        "            image_paths.append(f)\n",
        "            labels.append(label_idx)\n",
        "    return image_paths, labels, class_names\n",
        "\n",
        "def split_dataset(image_paths, labels, test_split=0.2, val_split=0.2, seed=SEED):\n",
        "    \"\"\"\n",
        "    Splits the data into Train (60%), Val (20%), Test (20%) with a fixed seed.\n",
        "    \"\"\"\n",
        "    # Step 1: separate out test set\n",
        "    trainval_paths, test_paths, trainval_labels, test_labels = train_test_split(\n",
        "        image_paths, labels,\n",
        "        test_size=test_split,\n",
        "        stratify=labels,\n",
        "        random_state=seed\n",
        "    )\n",
        "    # Step 2: separate out validation from train\n",
        "    relative_val_split = val_split / (1.0 - test_split)\n",
        "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "        trainval_paths, trainval_labels,\n",
        "        test_size=relative_val_split,\n",
        "        stratify=trainval_labels,\n",
        "        random_state=seed\n",
        "    )\n",
        "    return train_paths, train_labels, val_paths, val_labels, test_paths, test_labels\n",
        "    def load_64x64_color_image(path):\n",
        "      \"\"\"\n",
        "      Reads a 64x64 color image from 'path'.\n",
        "      If the image is not 64x64, forcibly resize. Then convert to float32 in [0,1].\n",
        "      \"\"\"\n",
        "      img = cv2.imread(path)\n",
        "      if img is None:\n",
        "          return None\n",
        "      img = cv2.resize(img, (64,64), interpolation=cv2.INTER_AREA)\n",
        "      img = img.astype(np.float32) / 255.0\n",
        "      return img\n",
        "\n",
        "    def convert_to_gray(img_bgr):\n",
        "      \"\"\"\n",
        "      Convert a float32 color image [0,1] to an 8-bit grayscale (uint8).\n",
        "      \"\"\"\n",
        "      gray_float = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
        "      gray_8u = (gray_float * 255).astype(np.uint8)\n",
        "      return gray_8u\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fayyk6XAMCeg"
      },
      "source": [
        "## Classical Feature Exctraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9e_KHimMDRS"
      },
      "source": [
        "###SIFT (512D Bag of Features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMvRQ-kuDq0T"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def create_sift_detector():\n",
        "    \"\"\"\n",
        "    Creates an OpenCV SIFT detector (requires opencv-contrib-python >=4.4).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return cv2.SIFT_create()\n",
        "    except AttributeError:\n",
        "        return cv2.xfeatures2d.SIFT_create()\n",
        "\n",
        "def extract_sift_descriptors(gray_8u, sift_detector):\n",
        "    \"\"\"\n",
        "    Extracts SIFT descriptors from an 8-bit grayscale image.\n",
        "    Returns (num_keypoints, 128) or None if no keypoints.\n",
        "    \"\"\"\n",
        "    kp, desc = sift_detector.detectAndCompute(gray_8u, None)\n",
        "    return desc\n",
        "\n",
        "def cluster_sift_descriptors_kmeans(all_desc, k=K_SIFT):\n",
        "    \"\"\"\n",
        "    Clusters all SIFT descriptors into k visual words (Bag-of-Features codebook).\n",
        "    We subsample if needed, up to MAX_DESCRIPTORS.\n",
        "    Returns a fitted KMeans object (sklearn).\n",
        "    \"\"\"\n",
        "    if all_desc.shape[0] > MAX_DESCRIPTORS:\n",
        "        idx = np.random.choice(all_desc.shape[0], MAX_DESCRIPTORS, replace=False)\n",
        "        all_desc = all_desc[idx]\n",
        "    print(f\"[SIFT] Running KMeans for Bag-of-Features (k={k}), descriptors shape={all_desc.shape}...\")\n",
        "    kmeans = KMeans(n_clusters=k, random_state=SEED, verbose=1)\n",
        "    kmeans.fit(all_desc)\n",
        "    print(\"[SIFT] KMeans clustering complete.\")\n",
        "    return kmeans\n",
        "\n",
        "def build_sift_bof_histogram(desc, kmeans_model, k=K_SIFT):\n",
        "    \"\"\"\n",
        "    Assign each local SIFT descriptor to nearest cluster => builds a k-dim histogram (Bag-of-Features).\n",
        "    L1-normalizes the histogram.\n",
        "    \"\"\"\n",
        "    if desc is None or len(desc) == 0:\n",
        "        return np.zeros(k, dtype=np.float32)\n",
        "    cluster_idxs = kmeans_model.predict(desc)\n",
        "    hist, _ = np.histogram(cluster_idxs, bins=np.arange(k+1), range=(0, k))\n",
        "    hist = hist.astype(np.float32)\n",
        "    hist_sum = hist.sum()\n",
        "    if hist_sum > 0:\n",
        "        hist /= hist_sum\n",
        "    return hist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TdpcomZMlHL"
      },
      "source": [
        "### HOG (512D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrjYgrufMNXH"
      },
      "outputs": [],
      "source": [
        "def extract_hog_features(gray_8u):\n",
        "    \"\"\"\n",
        "    Extracts HOG (skimage) => final dimension 512 by truncation/padding.\n",
        "    \"\"\"\n",
        "    hog_desc = hog(\n",
        "        gray_8u.astype(np.float32) / 255.0,\n",
        "        orientations=HOG_ORIENTATIONS,\n",
        "        pixels_per_cell=HOG_PIXELS_PER_CELL,\n",
        "        cells_per_block=HOG_CELLS_PER_BLOCK,\n",
        "        block_norm='L2-Hys',\n",
        "        transform_sqrt=False,\n",
        "        feature_vector=True\n",
        "    )\n",
        "    # Force dimension = HOG_DIM (512)\n",
        "    if hog_desc.shape[0] > HOG_DIM:\n",
        "        hog_desc = hog_desc[:HOG_DIM]\n",
        "    elif hog_desc.shape[0] < HOG_DIM:\n",
        "        pad_len = HOG_DIM - hog_desc.shape[0]\n",
        "        hog_desc = np.concatenate([hog_desc, np.zeros(pad_len, dtype=np.float32)])\n",
        "    return hog_desc.astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snk2abDHMoX4"
      },
      "source": [
        "###Colour Histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agwU1-tFMOJX"
      },
      "outputs": [],
      "source": [
        "def extract_color_hist(img_bgr, bins_per_channel=COLOR_BINS_PER_CHANNEL):\n",
        "    \"\"\"\n",
        "    Build a color histogram => 3 * bins_per_channel (~129D).\n",
        "    Each channel is float32[0,1], with (bins_per_channel) bins in [0,1].\n",
        "    \"\"\"\n",
        "    chans = cv2.split(img_bgr)\n",
        "    feats = []\n",
        "    for ch in chans:\n",
        "        hist = cv2.calcHist([ch], [0], None, [bins_per_channel], [0,1])\n",
        "        hist = cv2.normalize(hist, hist).flatten()\n",
        "        feats.append(hist)\n",
        "    feats = np.concatenate(feats).astype(np.float32)\n",
        "    return feats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u98-sYm2MrFc"
      },
      "source": [
        "\n",
        "###Canny Edge Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ54xUMGMTqT"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_canny_features(gray_8u, grid=CANNY_GRID,\n",
        "                           thresh1=CANNY_THRESHOLD1,\n",
        "                           thresh2=CANNY_THRESHOLD2):\n",
        "    \"\"\"\n",
        "    1) Canny edge detection\n",
        "    2) 8x8 grid => each cell=8x8 => count edges in each cell => 64D\n",
        "    3) L1 normalize\n",
        "    \"\"\"\n",
        "    edges = cv2.Canny(gray_8u, thresh1, thresh2)\n",
        "    h, w = edges.shape\n",
        "    gx, gy = grid\n",
        "    cell_h = h // gx\n",
        "    cell_w = w // gy\n",
        "\n",
        "    features = []\n",
        "    for i in range(gx):\n",
        "        for j in range(gy):\n",
        "            y1, y2 = i*cell_h, (i+1)*cell_h\n",
        "            x1, x2 = j*cell_w, (j+1)*cell_w\n",
        "            cell = edges[y1:y2, x1:x2]\n",
        "            count_edges = np.sum(cell > 0)\n",
        "            features.append(count_edges)\n",
        "    features = np.array(features, dtype=np.float32)\n",
        "    s = features.sum()\n",
        "    if s > 0:\n",
        "        features /= s\n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42eexUHoMulb"
      },
      "source": [
        "### LBP Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWzhhSbPMYzN"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_lbp_features(gray_8u, radius=LBP_RADIUS, n_points=LBP_POINTS):\n",
        "    \"\"\"\n",
        "    Extract LBP => uniform patterns => 10D hist for n_points=8.\n",
        "    L1 normalize.\n",
        "    \"\"\"\n",
        "    lbp = local_binary_pattern(gray_8u, n_points, radius, method='uniform')\n",
        "    hist_bins = n_points + 2\n",
        "    hist, _ = np.histogram(lbp.ravel(), bins=np.arange(hist_bins+1), range=(0, hist_bins))\n",
        "    hist = hist.astype(np.float32)\n",
        "    s = hist.sum()\n",
        "    if s > 0:\n",
        "        hist /= s\n",
        "    return hist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns2GZxvBMxh-"
      },
      "source": [
        "###Exctracting All Classicial Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auzucxwRMeMp"
      },
      "outputs": [],
      "source": [
        "def extract_all_features_classical(paths, labels=None, kmeans_sift=None):\n",
        "    \"\"\"\n",
        "    For each image path, build:\n",
        "        - SIFT -> 512D BoF (if kmeans_sift is not None)\n",
        "        - HOG  -> 512D\n",
        "        - Color-> ~129D\n",
        "        - Canny-> 64D\n",
        "        - LBP  -> 10D\n",
        "    Return a dict with arrays + 'Labels' if provided.\n",
        "    \"\"\"\n",
        "    sift_bof_list = []\n",
        "    hog_list = []\n",
        "    color_list = []\n",
        "    canny_list = []\n",
        "    lbp_list = []\n",
        "\n",
        "    sift_detector = create_sift_detector()\n",
        "\n",
        "    for path in tqdm(paths, desc=\"Extracting Features\"):\n",
        "        img_bgr = load_64x64_color_image(path)\n",
        "        if img_bgr is None:\n",
        "            # Could not load => fill with zeros\n",
        "            sift_bof_list.append(np.zeros(K_SIFT, dtype=np.float32))\n",
        "            hog_list.append(np.zeros(HOG_DIM, dtype=np.float32))\n",
        "            color_list.append(np.zeros(3*COLOR_BINS_PER_CHANNEL, dtype=np.float32))\n",
        "            canny_list.append(np.zeros(CANNY_GRID[0]*CANNY_GRID[1], dtype=np.float32))\n",
        "            lbp_list.append(np.zeros(LBP_POINTS+2, dtype=np.float32))\n",
        "            continue\n",
        "\n",
        "        gray_8u = convert_to_gray(img_bgr)\n",
        "\n",
        "        # SIFT\n",
        "        if kmeans_sift is not None:\n",
        "            desc = extract_sift_descriptors(gray_8u, sift_detector)\n",
        "            bof = build_sift_bof_histogram(desc, kmeans_sift, K_SIFT)\n",
        "        else:\n",
        "            # If kmeans_sift is None, we do not build a BoF yet\n",
        "            bof = np.zeros(K_SIFT, dtype=np.float32)\n",
        "        sift_bof_list.append(bof)\n",
        "\n",
        "        # HOG\n",
        "        hog_vec = extract_hog_features(gray_8u)\n",
        "        hog_list.append(hog_vec)\n",
        "\n",
        "        # Color\n",
        "        color_vec = extract_color_hist(img_bgr, COLOR_BINS_PER_CHANNEL)\n",
        "        color_list.append(color_vec)\n",
        "\n",
        "        # Canny\n",
        "        canny_vec = extract_canny_features(gray_8u, CANNY_GRID, CANNY_THRESHOLD1, CANNY_THRESHOLD2)\n",
        "        canny_list.append(canny_vec)\n",
        "\n",
        "        # LBP\n",
        "        lbp_vec = extract_lbp_features(gray_8u, LBP_RADIUS, LBP_POINTS)\n",
        "        lbp_list.append(lbp_vec)\n",
        "\n",
        "    feats_dict = {\n",
        "        \"SIFT\":  np.array(sift_bof_list, dtype=np.float32),\n",
        "        \"HOG\":   np.array(hog_list, dtype=np.float32),\n",
        "        \"Color\": np.array(color_list, dtype=np.float32),\n",
        "        \"Canny\": np.array(canny_list, dtype=np.float32),\n",
        "        \"LBP\":   np.array(lbp_list,   dtype=np.float32),\n",
        "    }\n",
        "    if labels is not None:\n",
        "        feats_dict[\"Labels\"] = np.array(labels, dtype=np.int32)\n",
        "    return feats_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oFr2_vwM3cH"
      },
      "source": [
        "\n",
        "## Deep Features (CNN & Tranformer Based)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CirNRRuM4Xd"
      },
      "source": [
        "###ImageDataset for all Deep Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_-nFuTKD0UF"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ImageDataset():\n",
        "    \"\"\"\n",
        "    Dataset that loads images from disk (64x64 or any size),\n",
        "    upscales to 224x224, transforms, etc.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, paths, labels=None, transform=None):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "        if self.labels is not None and len(self.paths) != len(self.labels):\n",
        "            raise ValueError(\"Mismatch between paths and labels length.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.paths[idx]\n",
        "        label = -1 if self.labels is None else self.labels[idx]\n",
        "        try:\n",
        "            img = Image.open(p).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            # if fail, produce a black 64x64\n",
        "            print(f\"[Warning] fail loading {p}: {e}\", file=sys.stderr)\n",
        "            img = Image.new(\"RGB\", (64,64), color=(0,0,0))\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gc-jaWDM-Z7"
      },
      "source": [
        "###RESNET152"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHSc9dyEEHZ-"
      },
      "outputs": [],
      "source": [
        "#Deep Features Extraction\n",
        "\n",
        "def create_resnet50_feature_extractor():\n",
        "    base_model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "    base_model.eval()\n",
        "    # strip final FC => keep up to global avgpool => 2048D\n",
        "    feature_extractor = nn.Sequential(*list(base_model.children())[:-1])\n",
        "    feature_extractor.eval()\n",
        "\n",
        "    # transform => upsample 64->224, etc.\n",
        "    transform = T.Compose([\n",
        "        T.Resize((224,224)),\n",
        "        T.ToTensor(),\n",
        "        T.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std =[0.229, 0.224, 0.225]\n",
        "        ),\n",
        "    ])\n",
        "    return feature_extractor, transform\n",
        "\n",
        "\n",
        "def extract_deep_features(paths, labels=None,\n",
        "                          batch_size=32, num_workers=0, device='cpu'):\n",
        "    \"\"\"\n",
        "    Returns {\"Deep\": (N,2048), \"Labels\": (N,)} if labels is not None\n",
        "    \"\"\"\n",
        "    feature_extractor, transform = create_resnet50_feature_extractor()\n",
        "    feature_extractor = feature_extractor.to(device)\n",
        "    feature_extractor.eval()\n",
        "\n",
        "    ds = ImageDataset(paths, labels=labels, transform=transform)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False,\n",
        "                    num_workers=num_workers,\n",
        "                    pin_memory=(device != 'cpu'))\n",
        "\n",
        "    all_feats = []\n",
        "    all_labels = [] if labels is not None else None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_imgs, batch_lbls in tqdm(dl, desc=\"Extracting Deep Feat\"):\n",
        "            batch_imgs = batch_imgs.to(device)\n",
        "            feats = feature_extractor(batch_imgs)  # shape: (B,2048,1,1)\n",
        "            feats = feats.view(feats.size(0), -1)   # => (B,2048)\n",
        "            feats_np = feats.cpu().numpy()          # => (B,2048)\n",
        "            all_feats.append(feats_np)\n",
        "            if labels is not None:\n",
        "                all_labels.extend(batch_lbls.numpy().tolist())\n",
        "\n",
        "    all_feats = np.concatenate(all_feats, axis=0).astype(np.float32)\n",
        "    out_dict = {\"Deep\": all_feats}\n",
        "    if labels is not None:\n",
        "        out_dict[\"Labels\"] = np.array(all_labels, dtype=np.int32)\n",
        "\n",
        "    return out_dict\n",
        "\n",
        "def concatenate_and_weight_features(feat_dict):\n",
        "    \"\"\"\n",
        "    Merges (SIFT,HOG,Color,Canny,LBP) horizontally, applying user-defined weights.\n",
        "    Returns X of shape (N, total_dim) and y of shape (N,) if \"Labels\" in feat_dict.\n",
        "    \"\"\"\n",
        "    # Weighted blocks\n",
        "    sift_bof = SIFT_WEIGHT  * feat_dict[\"SIFT\"]\n",
        "    hog      = HOG_WEIGHT   * feat_dict[\"HOG\"]\n",
        "    color    = COLOR_WEIGHT * feat_dict[\"Color\"]\n",
        "    canny    = CANNY_WEIGHT * feat_dict[\"Canny\"]\n",
        "    lbp      = LBP_WEIGHT   * feat_dict[\"LBP\"]\n",
        "\n",
        "    X = np.hstack([sift_bof, hog, color, canny, lbp])\n",
        "    y = feat_dict.get(\"Labels\", None)\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N_LclULNv3j"
      },
      "source": [
        "##Textual Features (Captioning + Sentence Embeddings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KU8ZhkbN1yK"
      },
      "source": [
        "###BLIP + SBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYYZ0PHhNjas"
      },
      "outputs": [],
      "source": [
        "\n",
        "def collate_blip_fn(batch):\n",
        "    imgs = [item[0] for item in batch]  # PIL images\n",
        "    lbls = [item[1] for item in batch]  # int labels\n",
        "    lbls_tensor = torch.tensor(lbls, dtype=torch.long)\n",
        "    return imgs, lbls_tensor\n",
        "\n",
        "class BlipImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Minimal dataset for BLIP: returns (PIL_image, label).\n",
        "    \"\"\"\n",
        "    def __init__(self, paths, labels=None):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        if self.labels is not None and len(self.paths) != len(self.labels):\n",
        "            raise ValueError(\"Mismatch in #paths vs #labels\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.paths[idx]\n",
        "        label = -1 if self.labels is None else self.labels[idx]\n",
        "        try:\n",
        "            img = Image.open(path).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            print(f\"[Warning] fail loading {path}: {e}\", file=sys.stderr)\n",
        "            img = Image.new(\"RGB\", (64,64), color=(0,0,0))\n",
        "        return img, label\n",
        "\n",
        "def extract_text_features_blip_sbert(paths, labels=None,\n",
        "                                     blip_model_name=BLIP_MODEL_NAME,\n",
        "                                     sbert_model_name=SBERT_MODEL_NAME,\n",
        "                                     batch_size=BATCH_SIZE_TEXT,\n",
        "                                     num_workers=NUM_WORKERS_TEXT,\n",
        "                                     device='cpu',\n",
        "                                     max_new_tokens=MAX_NEW_TOKENS):\n",
        "    \"\"\"\n",
        "    1) Generate one caption per image via BLIP\n",
        "    2) Embed each caption via SBERT => 768D\n",
        "    Returns { \"Captions\": list[str], \"TextEmbed\": (N,embed_dim), \"Labels\": (N,) }\n",
        "    \"\"\"\n",
        "    print(f\"[INFO] Loading BLIP model: {blip_model_name}\")\n",
        "    processor = BlipProcessor.from_pretrained(blip_model_name,use_fast = True)\n",
        "    blip_model = BlipForConditionalGeneration.from_pretrained(blip_model_name)\n",
        "    blip_model.to(device).eval()\n",
        "\n",
        "    print(f\"[INFO] Loading SBERT model: {sbert_model_name}\")\n",
        "    sbert_model = SentenceTransformer(sbert_model_name, device=device)\n",
        "\n",
        "    ds = BlipImageDataset(paths, labels=labels)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False,\n",
        "                    num_workers=num_workers, pin_memory=(device!='cpu'),\n",
        "                    collate_fn=collate_blip_fn)\n",
        "\n",
        "    all_captions = []\n",
        "    all_labels = [] if labels is not None else None\n",
        "\n",
        "    print(\"[INFO] Generating captions with BLIP ...\")\n",
        "    for batch_imgs, batch_lbls in tqdm(dl, desc=\"BLIP Captioning\"):\n",
        "        inputs = processor(images=batch_imgs, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            out = blip_model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
        "        for seq in out:\n",
        "            caption = processor.decode(seq, skip_special_tokens=True)\n",
        "            all_captions.append(caption)\n",
        "\n",
        "        if labels is not None:\n",
        "            all_labels.extend(batch_lbls.cpu().numpy().tolist())\n",
        "\n",
        "    print(\"[INFO] Embedding captions with SBERT ...\")\n",
        "    text_embeddings = sbert_model.encode(all_captions,\n",
        "                                         batch_size=batch_size,\n",
        "                                         convert_to_numpy=True,\n",
        "                                         show_progress_bar=True)\n",
        "    text_embeddings = text_embeddings.astype(np.float32)\n",
        "\n",
        "    result = {\n",
        "        \"Captions\" : all_captions,\n",
        "        \"TextEmbed\": text_embeddings\n",
        "    }\n",
        "    if labels is not None:\n",
        "        result[\"Labels\"] = np.array(all_labels, dtype=np.int32)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgpMAoyTOG6O"
      },
      "source": [
        "###Merging the Features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5J5fPVZN_h-"
      },
      "outputs": [],
      "source": [
        "def merge_classical_and_deep_feats(classical_dict, deep_dict):\n",
        "    \"\"\"\n",
        "    classical_dict =>\n",
        "       \"SIFT\"  (N, K_SIFT)\n",
        "       \"HOG\"   list of (N) elements, each hog array can vary in length\n",
        "       \"Color\" (N, 3*COLOR_BINS_PER_CHANNEL)\n",
        "       \"Canny\" (N, 64)\n",
        "       \"LBP\"   (N, 10)\n",
        "    deep_dict =>\n",
        "       \"Deep\"  (N, 2048)\n",
        "\n",
        "    We'll horizontally stack them by:\n",
        "    [SIFT, HOG, Color, Canny, LBP, Deep]\n",
        "\n",
        "    IMPORTANT: Because HOG length can vary if images differ or we do big resizes,\n",
        "    we must ensure each image is the same size. Since we forcibly resize to 512x512,\n",
        "    each hog vector *should* have the same dimension. We'll verify by the first image.\n",
        "    \"\"\"\n",
        "    sift_bof =  classical_dict[\"SIFT\"]  # (N, K_SIFT)\n",
        "    color    = classical_dict[\"Color\"] # (N, 3*bins)\n",
        "    canny    = classical_dict[\"Canny\"] # (N, 64)\n",
        "    lbp      = classical_dict[\"LBP\"]   # (N, 10)\n",
        "    deep_feats = deep_dict[\"Deep\"]                    # (N, 2048)\n",
        "\n",
        "    # Convert the list of hog arrays into a single 2D array\n",
        "    # (N, hog_dim).  We'll check dimension from the first.\n",
        "    hog_list = [np.array(hog) for hog in classical_dict[\"HOG\"]]\n",
        "    hog_dim = hog_list[0].shape[0] if len(hog_list) > 0 else 0\n",
        "    hog_stack = np.zeros((len(hog_list), hog_dim), dtype=np.float32)\n",
        "\n",
        "    for i, hv in enumerate(hog_list):\n",
        "        hog_stack[i, :] = hv\n",
        "\n",
        "    hog_stack *= HOG_WEIGHT  # (N, hog_dim)\n",
        "\n",
        "    # Now combine everything horizontally\n",
        "    X_classical = np.hstack([sift_bof, hog_stack, color, canny, lbp])\n",
        "    X_combined  = np.hstack([X_classical, deep_feats])\n",
        "    X_deep =np.hstack([deep_feats])\n",
        "\n",
        "    y = classical_dict[\"Labels\"]\n",
        "    return X_combined, y, X_classical, y, X_deep, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWh5dGlvOKbl"
      },
      "source": [
        "## Clustering Models & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqgg-YRJOd-d"
      },
      "source": [
        "###K-Means From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDsGxb36Oc6X"
      },
      "outputs": [],
      "source": [
        "def kmeans_plus_plus_init(X, k, random_state=42):\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    N, D = X.shape\n",
        "\n",
        "    # pick first center randomly\n",
        "    first_idx = rng.integers(0, N)\n",
        "    centers = [X[first_idx]]\n",
        "\n",
        "    for _ in range(k - 1):\n",
        "        # Distances to nearest center\n",
        "        dists = np.full(N, np.inf, dtype=np.float64)\n",
        "        for c in centers:\n",
        "            dist_sq = np.sum((X - c)**2, axis=1)\n",
        "            dists = np.minimum(dists, dist_sq)\n",
        "        prob = dists / np.sum(dists)\n",
        "        next_idx = rng.choice(N, p=prob)\n",
        "        centers.append(X[next_idx])\n",
        "    return np.array(centers, dtype=np.float64)\n",
        "\n",
        "def pairwise_distances(X, centers):\n",
        "    N, D = X.shape\n",
        "    k, _ = centers.shape\n",
        "    dist = np.empty((N, k), dtype=np.float64)\n",
        "    for j in range(k):\n",
        "        diff = X - centers[j]\n",
        "        dist[:, j] = np.sum(diff*diff, axis=1)\n",
        "    return dist\n",
        "\n",
        "def compute_inertia(X, centers, labels):\n",
        "    \"\"\"\n",
        "    Compute inertia: sum of squared distances of samples to their closest cluster center\n",
        "    \"\"\"\n",
        "    inertia = 0.0\n",
        "    for i in range(X.shape[0]):\n",
        "        center = centers[labels[i]]\n",
        "        inertia += np.sum((X[i] - center) ** 2)\n",
        "    return inertia\n",
        "\n",
        "def plot_elbow_curve(X, k_range, random_state=42):\n",
        "    inertias = []\n",
        "\n",
        "    for k in tqdm(k_range, desc=\"Computing Elbow Curve\"):\n",
        "        centers, labels = kmeans_advanced(X, k, random_state=random_state)\n",
        "        inertia = compute_inertia(X, centers, labels)\n",
        "        inertias.append(inertia)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(k_range, inertias, marker='o', linestyle='-', color='purple')\n",
        "    plt.xticks(k_range)\n",
        "    plt.xlabel(\"Number of Clusters (k)\")\n",
        "    plt.ylabel(\"Inertia (Sum of Squared Distances)\")\n",
        "    plt.title(\"Elbow Curve for K-Means\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "def kmeans_advanced(X, k, max_iter=300, tol=1e-4, init=\"kmeans++\", random_state=42):\n",
        "    \"\"\"\n",
        "    From-scratch K-Means:\n",
        "     - k-means++ initialization\n",
        "     - pairwise distance computation\n",
        "     - re-init empty clusters\n",
        "     - tolerance-based convergence\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    N, D = X.shape\n",
        "\n",
        "    if init == \"kmeans++\":\n",
        "        centers = kmeans_plus_plus_init(X, k, random_state)\n",
        "    elif init == \"random\":\n",
        "        idx = rng.choice(N, size=k, replace=False)\n",
        "        centers = X[idx].astype(np.float64)\n",
        "    else:\n",
        "        raise ValueError(\"init must be 'kmeans++' or 'random'\")\n",
        "\n",
        "    labels = np.zeros(N, dtype=np.int32)\n",
        "    for iteration in tqdm(range(max_iter), desc=\"K-Means Iter\"):\n",
        "        dist = pairwise_distances(X, centers)\n",
        "        new_labels = np.argmin(dist, axis=1)\n",
        "\n",
        "        # if no change in labels => converged\n",
        "        if np.all(labels == new_labels):\n",
        "            break\n",
        "\n",
        "        labels = new_labels\n",
        "\n",
        "        new_centers = np.zeros((k, D), dtype=np.float64)\n",
        "        counts = np.zeros(k, dtype=np.int32)\n",
        "        for i in range(N):\n",
        "            c_idx = labels[i]\n",
        "            new_centers[c_idx] += X[i]\n",
        "            counts[c_idx] += 1\n",
        "        for c_idx in range(k):\n",
        "            if counts[c_idx] == 0:\n",
        "                # re-init if empty cluster\n",
        "                rand_idx = rng.integers(0, N)\n",
        "                new_centers[c_idx] = X[rand_idx]\n",
        "                counts[c_idx] = 1\n",
        "            else:\n",
        "                new_centers[c_idx] /= counts[c_idx]\n",
        "\n",
        "        shift = np.sqrt(np.sum((centers - new_centers)**2))\n",
        "        centers = new_centers\n",
        "        if shift < tol:\n",
        "            break\n",
        "\n",
        "    return centers, labels\n",
        "\n",
        "\n",
        "def majority_label_for_clusters(labels_train, clusters_train, k):\n",
        "    \"\"\"\n",
        "    Each cluster is assigned the majority label of the training samples\n",
        "    that fall in that cluster. If a cluster is empty, assign -1 (unlabeled).\n",
        "    \"\"\"\n",
        "    cluster_label_map = np.zeros(k, dtype=np.int32)\n",
        "    for c_idx in range(k):\n",
        "        mask = (clusters_train == c_idx)\n",
        "        if not np.any(mask):\n",
        "            cluster_label_map[c_idx] = -1\n",
        "            continue\n",
        "        cluster_labels = labels_train[mask]\n",
        "        vals, counts = np.unique(cluster_labels, return_counts=True)\n",
        "        majority_class = vals[np.argmax(counts)]\n",
        "        cluster_label_map[c_idx] = majority_class\n",
        "    return cluster_label_map\n",
        "\n",
        "def classify_with_kmeans(X, centers, cluster_label_map):\n",
        "    dist = pairwise_distances(X, centers)\n",
        "    nearest = np.argmin(dist, axis=1)\n",
        "    preds = cluster_label_map[nearest]\n",
        "    return preds\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1tAgD7TOhyU"
      },
      "source": [
        "###Agglomerative Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRd7kICQEIW4"
      },
      "outputs": [],
      "source": [
        "#Clustering Helpers\n",
        "\n",
        "def majority_label_for_dbscan(labels_train, clusters_train):\n",
        "    unique_clusters = np.unique(clusters_train)\n",
        "    cluster_label_map = {}\n",
        "\n",
        "    for c_idx in unique_clusters:\n",
        "        mask = (clusters_train == c_idx)\n",
        "        if not np.any(mask):\n",
        "            cluster_label_map[c_idx] = -1\n",
        "            continue\n",
        "\n",
        "        cluster_labels = labels_train[mask]\n",
        "        vals, counts = np.unique(cluster_labels, return_counts=True)\n",
        "        majority_class = vals[np.argmax(counts)]\n",
        "        cluster_label_map[c_idx] = majority_class\n",
        "\n",
        "    return cluster_label_map\n",
        "\n",
        "def predict_with_dbscan(X_train, train_cluster_assignments, X_test, cluster_label_map):\n",
        "    # Find nearest training sample for each test sample\n",
        "    test_preds = classify_by_nearest_train(X_test, X_train, train_cluster_assignments)\n",
        "\n",
        "    # Map cluster assignments to class labels\n",
        "    result = np.zeros(len(test_preds), dtype=np.int32)\n",
        "    for i, cluster in enumerate(test_preds):\n",
        "        result[i] = cluster_label_map.get(cluster, -1)\n",
        "\n",
        "    return result\n",
        "\n",
        "def run_hierarchical_clustering(X_train, y_train, X_val, y_val, X_test, y_test, n_clusters=30, linkage='ward'):\n",
        "    print(f\"\\n[INFO] Running Hierarchical Clustering with {n_clusters} clusters, {linkage} linkage...\")\n",
        "\n",
        "    # Train the model\n",
        "    agg_model = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)\n",
        "    train_agg_labels = agg_model.fit_predict(X_train)\n",
        "\n",
        "    # Map clusters to majority labels\n",
        "    cluster_map_agg = majority_label_for_dbscan(y_train, train_agg_labels)\n",
        "\n",
        "    # Predict on validation set\n",
        "    val_pred_agg = predict_with_dbscan(X_train, train_agg_labels, X_val, cluster_map_agg)\n",
        "    val_acc_agg = accuracy_score(y_val, val_pred_agg)\n",
        "    val_ari_agg = adjusted_rand_score(y_val, val_pred_agg)\n",
        "    print(f\"[Hierarchical] Val Accuracy= {val_acc_agg:.4f}, Val ARI= {val_ari_agg:.4f}\")\n",
        "\n",
        "    # Predict on test set\n",
        "    test_pred_agg = predict_with_dbscan(X_train, train_agg_labels, X_test, cluster_map_agg)\n",
        "    test_acc_agg = accuracy_score(y_test, test_pred_agg)\n",
        "    test_ari_agg = adjusted_rand_score(y_test, test_pred_agg)\n",
        "    print(f\"[Hierarchical] Test Accuracy= {test_acc_agg:.4f}, Test ARI= {test_ari_agg:.4f}\")\n",
        "\n",
        "    # Visualization code could be added here for hierarchical clusters\n",
        "\n",
        "    return {\n",
        "        'val_accuracy': val_acc_agg,\n",
        "        'val_ari': val_ari_agg,\n",
        "        'test_accuracy': test_acc_agg,\n",
        "        'test_ari': test_ari_agg\n",
        "    }\n",
        "#Agglomerative Clustering and K means\n",
        "def run_agglomerative_clustering(X_train_all, y_train_all, X_val_all, y_val_all, X_test_all, y_test_all):\n",
        "    print(\"\\n[INFO] Running Agglomerative Clustering (sklearn) ...\")\n",
        "    n_clusters_agg = 54  # Can be tuned based on dataset\n",
        "    linkage_options = ['ward','complete','average']\n",
        "\n",
        "    best_val_acc = 0\n",
        "    best_linkage = None\n",
        "    best_results = None\n",
        "\n",
        "    # Try different linkage methods\n",
        "    for linkage_agg in linkage_options:\n",
        "        print(f\"\\n[INFO] Testing linkage method: {linkage_agg}\")\n",
        "\n",
        "        # Train the model\n",
        "        agg_model = AgglomerativeClustering(n_clusters=n_clusters_agg, linkage=linkage_agg)\n",
        "        train_agg_labels = agg_model.fit_predict(X_train_all)\n",
        "\n",
        "        # Map clusters to majority labels\n",
        "        cluster_map_agg = majority_label_for_dbscan(y_train_all, train_agg_labels)\n",
        "\n",
        "        # Predict on validation set\n",
        "        val_pred_agg = predict_with_dbscan(X_train_all, train_agg_labels, X_val_all, cluster_map_agg)\n",
        "        val_acc_agg = accuracy_score(y_val_all, val_pred_agg)\n",
        "        val_ari_agg = adjusted_rand_score(y_val_all, val_pred_agg)\n",
        "        print(f\"[Agglomerative {linkage_agg}] Val Accuracy= {val_acc_agg:.4f}, Val ARI= {val_ari_agg:.4f}\")\n",
        "\n",
        "        # Track best performance\n",
        "        if val_acc_agg > best_val_acc:\n",
        "            best_val_acc = val_acc_agg\n",
        "            best_linkage = linkage_agg\n",
        "\n",
        "            # Predict on test set\n",
        "            test_pred_agg = predict_with_dbscan(X_train_all, train_agg_labels, X_test_all, cluster_map_agg)\n",
        "            test_acc_agg = accuracy_score(y_test_all, test_pred_agg)\n",
        "            test_ari_agg = adjusted_rand_score(y_test_all, test_pred_agg)\n",
        "            best_results = {\n",
        "                'linkage': linkage_agg,\n",
        "                'val_accuracy': val_acc_agg,\n",
        "                'val_ari': val_ari_agg,\n",
        "                'test_accuracy': test_acc_agg,\n",
        "                'test_ari': test_ari_agg\n",
        "            }\n",
        "\n",
        "    print(f\"\\n[INFO] Best Agglomerative Clustering results with linkage={best_linkage}:\")\n",
        "    print(f\"[Agglomerative] Val Accuracy= {best_results['val_accuracy']:.4f}, Val ARI= {best_results['val_ari']:.4f}\")\n",
        "    print(f\"[Agglomerative] Test Accuracy= {best_results['test_accuracy']:.4f}, Test ARI= {best_results['test_ari']:.4f}\")\n",
        "\n",
        "    # Visualize clusters with t-SNE\n",
        "    visualize_agglomerative_clusters(X_train_all, y_train_all, best_linkage, n_clusters_agg)\n",
        "\n",
        "    return best_results\n",
        "\n",
        "def visualize_agglomerative_clusters(X_train, y_train, linkage_method, n_clusters, random_state=42):\n",
        "    \"\"\"\n",
        "    Visualize agglomerative clusters using t-SNE\n",
        "    \"\"\"\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.manifold import TSNE\n",
        "\n",
        "    print(\"[INFO] Visualizing Agglomerative clusters with t-SNE...\")\n",
        "\n",
        "    # Run agglomerative clustering\n",
        "    agg_model = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage_method)\n",
        "    clusters = agg_model.fit_predict(X_train)\n",
        "\n",
        "    # Apply t-SNE for visualization\n",
        "    tsne = TSNE(n_components=2, random_state=random_state, perplexity=30, n_iter=1000)\n",
        "    X_tsne = tsne.fit_transform(X_train)\n",
        "\n",
        "    # Create plots\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "    # Plot 1: Show clusters\n",
        "    scatter1 = ax1.scatter(X_tsne[:, 0], X_tsne[:, 1], c=clusters, cmap='viridis', alpha=0.7, s=30)\n",
        "    ax1.set_title(f'Agglomerative Clustering (n={n_clusters}, linkage={linkage_method})')\n",
        "    ax1.set_xlabel('t-SNE Component 1')\n",
        "    ax1.set_ylabel('t-SNE Component 2')\n",
        "    fig.colorbar(scatter1, ax=ax1, label='Cluster')\n",
        "    ax1.grid(alpha=0.3)\n",
        "\n",
        "    # Plot 2: Show true labels\n",
        "    scatter2 = ax2.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y_train, cmap='viridis', alpha=0.7, s=30)\n",
        "    ax2.set_title('True Labels')\n",
        "    ax2.set_xlabel('t-SNE Component 1')\n",
        "    ax2.set_ylabel('t-SNE Component 2')\n",
        "    fig.colorbar(scatter2, ax=ax2, label='True Label')\n",
        "    ax2.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('agglomerative_clusters_tsne.png')\n",
        "    plt.show()\n",
        "\n",
        "def majority_label_for_clusters(labels_train, clusters_train, k):\n",
        "    cluster_label_map = np.zeros(k, dtype=np.int32)\n",
        "    for c_idx in range(k):\n",
        "        mask = (clusters_train == c_idx)\n",
        "        if not np.any(mask):\n",
        "            # handle empty cluster\n",
        "            cluster_label_map[c_idx] = -1\n",
        "            continue\n",
        "        cluster_labels = labels_train[mask]\n",
        "        vals, counts = np.unique(cluster_labels, return_counts=True)\n",
        "        majority_class = vals[np.argmax(counts)]\n",
        "        cluster_label_map[c_idx] = majority_class\n",
        "    return cluster_label_map\n",
        "\n",
        "def pairwise_distances(X, Y):\n",
        "    # naive O(N*M*D) approach\n",
        "    # returns dist[i, j] = ||X[i] - Y[j]||^2\n",
        "    # for classification with dbscan/kmeans\n",
        "    N, D = X.shape\n",
        "    M, _ = Y.shape\n",
        "    dist = np.empty((N, M), dtype=np.float32)\n",
        "    for j in range(M):\n",
        "        diff = X - Y[j]\n",
        "        dist[:, j] = np.sum(diff*diff, axis=1)\n",
        "    return dist\n",
        "\n",
        "def classify_by_nearest_train(X_test, X_train, train_cluster_assignments):\n",
        "    \"\"\"\n",
        "    A naive approach for cluster-based classification with methods\n",
        "    that do not define a 'predict' for new data (like DBSCAN).\n",
        "    For each test sample => find the nearest training sample =>\n",
        "    assign the same cluster label.\n",
        "    \"\"\"\n",
        "    dists = pairwise_distances(X_test, X_train)  # shape (Ntest, Ntrain)\n",
        "    nearest_idx = np.argmin(dists, axis=1)\n",
        "    assigned_clusters = train_cluster_assignments[nearest_idx]\n",
        "    return assigned_clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EsV9nUMO7e2"
      },
      "source": [
        "###Evaluation & TSNE Plots on KMeans and Agglomerative Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1tqZiPPEp1V"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, adjusted_rand_score\n",
        "\n",
        "\n",
        "def run_all_evaluations(X_train_all,y_train_all,X_val_all,y_val_all,X_test_all,y_test_all):\n",
        "\n",
        "    #--------------------------------------------------------------------------\n",
        "    # 7) Scale + PCA\n",
        "    #--------------------------------------------------------------------------\n",
        "    if APPLY_SCALING:\n",
        "        print(\"[INFO] Applying StandardScaler...\")\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(X_train_all)\n",
        "        X_train_all = scaler.transform(X_train_all)\n",
        "        X_val_all   = scaler.transform(X_val_all)\n",
        "        X_test_all  = scaler.transform(X_test_all)\n",
        "\n",
        "    if APPLY_PCA:\n",
        "\n",
        "        pca = PCA(n_components=0.95, random_state=SEED)\n",
        "        pca.fit(X_train_all)\n",
        "        X_train_all = pca.transform(X_train_all)\n",
        "        X_val_all   = pca.transform(X_val_all)\n",
        "        X_test_all  = pca.transform(X_test_all)\n",
        "        print(f\"[INFO] PCA variance ratio sum= {pca.explained_variance_ratio_.sum():.4f}\")\n",
        "\n",
        "    print(\"[INFO] Running from-scratch K-Means classification...\")\n",
        "    centers, clusters_train = kmeans_advanced(\n",
        "        X_train_all, k=KMEANS_CLUSTERS, max_iter=300, tol=1e-4,\n",
        "        init=\"kmeans++\", random_state=SEED\n",
        "    )\n",
        "    cluster_label_map = majority_label_for_clusters(y_train_all, clusters_train, KMEANS_CLUSTERS)\n",
        "\n",
        "    # Val\n",
        "    val_preds = classify_with_kmeans(X_val_all, centers, cluster_label_map)\n",
        "    val_acc = accuracy_score(y_val_all, val_preds)\n",
        "    val_ari = adjusted_rand_score(y_val_all, val_preds)\n",
        "    print(f\"[K-Means] Val Accuracy= {val_acc:.4f}, Val ARI= {val_ari:.4f}\")\n",
        "\n",
        "    # Test\n",
        "    test_preds = classify_with_kmeans(X_test_all, centers, cluster_label_map)\n",
        "    test_acc = accuracy_score(y_test_all, test_preds)\n",
        "    test_ari = adjusted_rand_score(y_test_all, test_preds)\n",
        "    print(f\"[K-Means] Test Accuracy= {test_acc:.4f}, Test ARI= {test_ari:.4f}\")\n",
        "    print(\"[INFO] Running from-scratch K-Means classification...\")\n",
        "\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    from sklearn.manifold import TSNE\n",
        "\n",
        "    print(\"[INFO] Visualizing K-means clusters with t-SNE...\")\n",
        "\n",
        "    # Combine training data and cluster centers for a single t-SNE fit\n",
        "    combined_data = np.vstack((X_train_all, centers))\n",
        "    tsne = TSNE(n_components=2, random_state=SEED, perplexity=30, n_iter=1000)\n",
        "    combined_tsne = tsne.fit_transform(combined_data)\n",
        "\n",
        "    # Separate transformed training data and cluster centers\n",
        "    X_train_tsne = combined_tsne[:len(X_train_all)]\n",
        "    centers_tsne = combined_tsne[len(X_train_all):]\n",
        "\n",
        "    # === Plot 1: K-means cluster visualization ===\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter = plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1],\n",
        "                        c=clusters_train, cmap='viridis', alpha=0.7, s=30)\n",
        "\n",
        "    # Plot cluster centers\n",
        "    plt.scatter(centers_tsne[:, 0], centers_tsne[:, 1],\n",
        "                c='red', marker='X', s=200, edgecolors='black', label='Cluster Centers')\n",
        "\n",
        "    plt.colorbar(scatter, label='Cluster Label')\n",
        "    plt.title('t-SNE Visualization of K-means Clusters')\n",
        "    plt.xlabel('t-SNE Component 1')\n",
        "    plt.ylabel('t-SNE Component 2')\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('kmeans_clusters_tsne.png')\n",
        "    plt.show()\n",
        "\n",
        "    # === Plot 2: True labels visualization ===\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter = plt.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1],\n",
        "                        c=y_train_all, cmap='viridis', alpha=0.7, s=30)\n",
        "\n",
        "    plt.colorbar(scatter, label='True Label')\n",
        "    plt.title('t-SNE Visualization with True Labels')\n",
        "    plt.xlabel('t-SNE Component 1')\n",
        "    plt.ylabel('t-SNE Component 2')\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('true_labels_tsne.png')\n",
        "    plt.show()\n",
        "    run_agglomerative_clustering(X_train_all, y_train_all, X_val_all, y_val_all, X_test_all, y_test_all)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--Hl1el9O4EH"
      },
      "source": [
        "##Main Pipeline ( 60/20/20 Train-Test-Val Split, feature extraction, Evaluation and Hyper parameter Tuning )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYao-PI3EvVX"
      },
      "outputs": [],
      "source": [
        "\n",
        "def main_pipeline():\n",
        "    print(\"[INFO] Loading dataset paths...\")\n",
        "    all_paths, all_labels, class_names = load_dataset_paths(DATA_DIR)\n",
        "    print(f\"Total images: {len(all_paths)}, Classes: {len(class_names)}\")\n",
        "\n",
        "    # Split the dataset\n",
        "    print(\"[INFO] Splitting dataset 60/20/20 ...\")\n",
        "    train_paths, train_labels, val_paths, val_labels, test_paths, test_labels = split_dataset(\n",
        "        all_paths, all_labels, TEST_SPLIT, VAL_SPLIT, SEED\n",
        "    )\n",
        "    print(f\"Train size= {len(train_paths)}, Val size= {len(val_paths)}, Test size= {len(test_paths)}\")\n",
        "\n",
        "    #--------------------------------------------------------------------------\n",
        "    # 1) SIFT Codebook (KMeans) caching\n",
        "    #--------------------------------------------------------------------------\n",
        "    codebook_pickle_path = \"sift_codebook_kmeans.pkl\"\n",
        "\n",
        "    if os.path.exists(codebook_pickle_path):\n",
        "        print(f\"[INFO] Loading existing SIFT codebook from {codebook_pickle_path}\")\n",
        "        with open(codebook_pickle_path, \"rb\") as f:\n",
        "            kmeans_sift = pickle.load(f)\n",
        "    else:\n",
        "        print(\"[INFO] Collecting Train SIFT descriptors...\")\n",
        "        desc_list = []\n",
        "        sift_detector = create_sift_detector()\n",
        "\n",
        "        for p in tqdm(train_paths, desc=\"Collecting Train SIFT\"):\n",
        "            img_bgr =  load_64x64_color_image(p)\n",
        "            if img_bgr is None:\n",
        "                continue\n",
        "            gray_8u = convert_to_gray(img_bgr)\n",
        "            desc = extract_sift_descriptors(gray_8u, sift_detector)\n",
        "            if desc is not None and len(desc) > 0:\n",
        "                desc_list.append(desc)\n",
        "\n",
        "        if len(desc_list) == 0:\n",
        "            raise ValueError(\"No SIFT descriptors found for training set!\")\n",
        "        all_train_desc = np.vstack(desc_list)\n",
        "        print(f\"[INFO] All train SIFT descriptors shape= {all_train_desc.shape}\")\n",
        "\n",
        "        print(f\"[INFO] Fitting KMeans codebook (k={K_SIFT}) for SIFT...\")\n",
        "        kmeans_sift = cluster_sift_descriptors_kmeans(all_train_desc, k=K_SIFT)\n",
        "\n",
        "        with open(codebook_pickle_path, \"wb\") as f:\n",
        "            pickle.dump(kmeans_sift, f)\n",
        "        print(f\"[INFO] Saved SIFT codebook to {codebook_pickle_path}\")\n",
        "\n",
        "    #--------------------------------------------------------------------------\n",
        "    # 2) Classical features caching: train, val, test\n",
        "    #--------------------------------------------------------------------------\n",
        "    classical_cache_train = \"train_classical_feats.npz\"\n",
        "    classical_cache_val   = \"val_classical_feats.npz\"\n",
        "    classical_cache_test  = \"test_classical_feats.npz\"\n",
        "\n",
        "    if os.path.exists(classical_cache_train) and REUSE_classical:\n",
        "        print(f\"[INFO] Loading cached train classical features from {classical_cache_train}\")\n",
        "        data_train = np.load(classical_cache_train, allow_pickle=True)\n",
        "        train_classical = {\n",
        "            \"SIFT\":  data_train[\"SIFT\"],\n",
        "            \"HOG\":   data_train[\"HOG\"].tolist(),\n",
        "            \"Color\": data_train[\"Color\"],\n",
        "            \"Canny\": data_train[\"Canny\"],\n",
        "            \"LBP\":   data_train[\"LBP\"],\n",
        "            \"Labels\": data_train[\"Labels\"],\n",
        "        }\n",
        "    else:\n",
        "        print(\"[INFO] Extracting classical features (train set)...\")\n",
        "        train_classical = extract_all_features_classical(train_paths, train_labels, kmeans_sift)\n",
        "        # We must store HOG as an object array or list, so we do:\n",
        "        np.savez(\n",
        "            classical_cache_train,\n",
        "            SIFT=train_classical[\"SIFT\"],\n",
        "            HOG=np.array(train_classical[\"HOG\"], dtype=object),\n",
        "            Color=train_classical[\"Color\"],\n",
        "            Canny=train_classical[\"Canny\"],\n",
        "            LBP=train_classical[\"LBP\"],\n",
        "            Labels=train_classical[\"Labels\"]\n",
        "        )\n",
        "        print(f\"[INFO] Saved train classical features to {classical_cache_train}\")\n",
        "\n",
        "    if os.path.exists(classical_cache_val) and REUSE_classical:\n",
        "        print(f\"[INFO] Loading cached val classical features from {classical_cache_val}\")\n",
        "        data_val = np.load(classical_cache_val, allow_pickle=True)\n",
        "        val_classical = {\n",
        "            \"SIFT\":  data_val[\"SIFT\"],\n",
        "            \"HOG\":   data_val[\"HOG\"].tolist(),\n",
        "            \"Color\": data_val[\"Color\"],\n",
        "            \"Canny\": data_val[\"Canny\"],\n",
        "            \"LBP\":   data_val[\"LBP\"],\n",
        "            \"Labels\": data_val[\"Labels\"],\n",
        "        }\n",
        "    else:\n",
        "        print(\"[INFO] Extracting classical features (val set)...\")\n",
        "        val_classical = extract_all_features_classical(val_paths, val_labels, kmeans_sift)\n",
        "        np.savez(\n",
        "            classical_cache_val,\n",
        "            SIFT=val_classical[\"SIFT\"],\n",
        "            HOG=np.array(val_classical[\"HOG\"], dtype=object),\n",
        "            Color=val_classical[\"Color\"],\n",
        "            Canny=val_classical[\"Canny\"],\n",
        "            LBP=val_classical[\"LBP\"],\n",
        "            Labels=val_classical[\"Labels\"]\n",
        "        )\n",
        "        print(f\"[INFO] Saved val classical features to {classical_cache_val}\")\n",
        "\n",
        "    if os.path.exists(classical_cache_test) and REUSE_classical:\n",
        "        print(f\"[INFO] Loading cached test classical features from {classical_cache_test}\")\n",
        "        data_test = np.load(classical_cache_test, allow_pickle=True)\n",
        "        test_classical = {\n",
        "            \"SIFT\":  data_test[\"SIFT\"],\n",
        "            \"HOG\":   data_test[\"HOG\"].tolist(),\n",
        "            \"Color\": data_test[\"Color\"],\n",
        "            \"Canny\": data_test[\"Canny\"],\n",
        "            \"LBP\":   data_test[\"LBP\"],\n",
        "            \"Labels\": data_test[\"Labels\"],\n",
        "        }\n",
        "    else:\n",
        "        print(\"[INFO] Extracting classical features (test set)...\")\n",
        "        test_classical = extract_all_features_classical(test_paths, test_labels, kmeans_sift)\n",
        "        np.savez(\n",
        "            classical_cache_test,\n",
        "            SIFT=test_classical[\"SIFT\"],\n",
        "            HOG=np.array(test_classical[\"HOG\"], dtype=object),\n",
        "            Color=test_classical[\"Color\"],\n",
        "            Canny=test_classical[\"Canny\"],\n",
        "            LBP=test_classical[\"LBP\"],\n",
        "            Labels=test_classical[\"Labels\"]\n",
        "        )\n",
        "        print(f\"[INFO] Saved test classical features to {classical_cache_test}\")\n",
        "\n",
        "    #--------------------------------------------------------------------------\n",
        "    # 3) Extract deep features (optionally cached)\n",
        "    #--------------------------------------------------------------------------\n",
        "    deep_cache_train = \"train_deep_feats.npz\"\n",
        "    deep_cache_val   = \"val_deep_feats.npz\"\n",
        "    deep_cache_test  = \"test_deep_feats.npz\"\n",
        "\n",
        "    if os.path.exists(deep_cache_train) and REUSE_deep:\n",
        "        print(f\"[INFO] Loading cached train deep features from {deep_cache_train}\")\n",
        "        data_deep_train = np.load(deep_cache_train, allow_pickle=True)\n",
        "        train_deep = {\n",
        "            \"Deep\": data_deep_train[\"Deep\"],\n",
        "            \"Labels\": data_deep_train[\"Labels\"]\n",
        "        }\n",
        "    else:\n",
        "        print(\"[INFO] Extracting deep features (train set) ...\")\n",
        "        train_deep = extract_deep_features(train_paths, train_labels,\n",
        "                                           batch_size=BATCH_SIZE_DEEP,\n",
        "                                           num_workers=NUM_WORKERS_DEEP,\n",
        "                                           device=DEVICE)\n",
        "        np.savez(\n",
        "            deep_cache_train,\n",
        "            Deep=train_deep[\"Deep\"],\n",
        "            Labels=train_deep[\"Labels\"]\n",
        "        )\n",
        "\n",
        "    if os.path.exists(deep_cache_val) and REUSE_deep:\n",
        "        print(f\"[INFO] Loading cached val deep features from {deep_cache_val}\")\n",
        "        data_deep_val = np.load(deep_cache_val, allow_pickle=True)\n",
        "        val_deep = {\n",
        "            \"Deep\": data_deep_val[\"Deep\"],\n",
        "            \"Labels\": data_deep_val[\"Labels\"]\n",
        "        }\n",
        "    else:\n",
        "        print(\"[INFO] Extracting deep features (val set) ...\")\n",
        "        val_deep = extract_deep_features(val_paths, val_labels,\n",
        "                                         batch_size=BATCH_SIZE_DEEP,\n",
        "                                         num_workers=NUM_WORKERS_DEEP,\n",
        "                                         device=DEVICE)\n",
        "        np.savez(\n",
        "            deep_cache_val,\n",
        "            Deep=val_deep[\"Deep\"],\n",
        "            Labels=val_deep[\"Labels\"]\n",
        "        )\n",
        "\n",
        "    if os.path.exists(deep_cache_test) and REUSE_deep:\n",
        "        print(f\"[INFO] Loading cached test deep features from {deep_cache_test}\")\n",
        "        data_deep_test = np.load(deep_cache_test, allow_pickle=True)\n",
        "        test_deep = {\n",
        "            \"Deep\": data_deep_test[\"Deep\"],\n",
        "            \"Labels\": data_deep_test[\"Labels\"]\n",
        "        }\n",
        "    else:\n",
        "        print(\"[INFO] Extracting deep features (test set) ...\")\n",
        "        test_deep = extract_deep_features(test_paths, test_labels,\n",
        "                                          batch_size=BATCH_SIZE_DEEP,\n",
        "                                          num_workers=NUM_WORKERS_DEEP,\n",
        "                                          device=DEVICE)\n",
        "        np.savez(\n",
        "            deep_cache_test,\n",
        "            Deep=test_deep[\"Deep\"],\n",
        "            Labels=test_deep[\"Labels\"]\n",
        "        )\n",
        "\n",
        "    #--------------------------------------------------------------------------\n",
        "    # 4) Text features (BLIP + SBERT)\n",
        "    #--------------------------------------------------------------------------\n",
        "    text_cache_train = \"train_text_feats.npz\"\n",
        "    text_cache_val   = \"val_text_feats.npz\"\n",
        "    text_cache_test  = \"test_text_feats.npz\"\n",
        "\n",
        "    def load_text_feats(cache_path):\n",
        "        dd = np.load(cache_path, allow_pickle=True)\n",
        "        return {\n",
        "            \"Captions\" : dd[\"Captions\"].tolist(),\n",
        "            \"TextEmbed\": dd[\"TextEmbed\"],\n",
        "            \"Labels\"   : dd[\"Labels\"]\n",
        "        }\n",
        "\n",
        "    # train\n",
        "    if os.path.exists(text_cache_train) and REUSE_text:\n",
        "        print(f\"[INFO] Loading cached train text feats from {text_cache_train}\")\n",
        "        dtr = np.load(text_cache_train, allow_pickle=True)\n",
        "        train_text = {\n",
        "            \"Captions\" : dtr[\"Captions\"].tolist(),\n",
        "            \"TextEmbed\": dtr[\"TextEmbed\"],\n",
        "            \"Labels\"   : dtr[\"Labels\"]\n",
        "        }\n",
        "    else:\n",
        "        print(\"[INFO] Extracting text features (train set) ...\")\n",
        "        train_text = extract_text_features_blip_sbert(\n",
        "            train_paths, train_labels,\n",
        "            blip_model_name=BLIP_MODEL_NAME,\n",
        "            sbert_model_name=SBERT_MODEL_NAME,\n",
        "            batch_size=BATCH_SIZE_TEXT,\n",
        "            num_workers=NUM_WORKERS_TEXT,\n",
        "            device=DEVICE,\n",
        "            max_new_tokens=MAX_NEW_TOKENS\n",
        "        )\n",
        "        np.savez(\n",
        "            text_cache_train,\n",
        "            Captions=np.array(train_text[\"Captions\"], dtype=object),\n",
        "            TextEmbed=train_text[\"TextEmbed\"],\n",
        "            Labels=train_text[\"Labels\"]\n",
        "        )\n",
        "\n",
        "    # val\n",
        "    if os.path.exists(text_cache_val) and REUSE_text:\n",
        "        print(f\"[INFO] Loading cached val text feats from {text_cache_val}\")\n",
        "        dv = np.load(text_cache_val, allow_pickle=True)\n",
        "        val_text = {\n",
        "            \"Captions\" : dv[\"Captions\"].tolist(),\n",
        "            \"TextEmbed\": dv[\"TextEmbed\"],\n",
        "            \"Labels\"   : dv[\"Labels\"]\n",
        "        }\n",
        "    else:\n",
        "        print(\"[INFO] Extracting text features (val set) ...\")\n",
        "        val_text = extract_text_features_blip_sbert(\n",
        "            val_paths, val_labels,\n",
        "            blip_model_name=BLIP_MODEL_NAME,\n",
        "            sbert_model_name=SBERT_MODEL_NAME,\n",
        "            batch_size=BATCH_SIZE_TEXT,\n",
        "            num_workers=NUM_WORKERS_TEXT,\n",
        "            device=DEVICE,\n",
        "            max_new_tokens=MAX_NEW_TOKENS\n",
        "        )\n",
        "        np.savez(\n",
        "            text_cache_val,\n",
        "            Captions=np.array(val_text[\"Captions\"], dtype=object),\n",
        "            TextEmbed=val_text[\"TextEmbed\"],\n",
        "            Labels=val_text[\"Labels\"]\n",
        "        )\n",
        "\n",
        "    # test\n",
        "    if os.path.exists(text_cache_test) and REUSE_text:\n",
        "        print(f\"[INFO] Loading cached test text feats from {text_cache_test}\")\n",
        "        dte = np.load(text_cache_test, allow_pickle=True)\n",
        "        test_text = {\n",
        "            \"Captions\" : dte[\"Captions\"].tolist(),\n",
        "            \"TextEmbed\": dte[\"TextEmbed\"],\n",
        "            \"Labels\"   : dte[\"Labels\"]\n",
        "        }\n",
        "    else:\n",
        "        print(\"[INFO] Extracting text features (test set) ...\")\n",
        "        test_text = extract_text_features_blip_sbert(\n",
        "            test_paths, test_labels,\n",
        "            blip_model_name=BLIP_MODEL_NAME,\n",
        "            sbert_model_name=SBERT_MODEL_NAME,\n",
        "            batch_size=BATCH_SIZE_TEXT,\n",
        "            num_workers=NUM_WORKERS_TEXT,\n",
        "            device=DEVICE,\n",
        "            max_new_tokens=MAX_NEW_TOKENS\n",
        "        )\n",
        "        np.savez(\n",
        "            text_cache_test,\n",
        "            Captions=np.array(test_text[\"Captions\"], dtype=object),\n",
        "            TextEmbed=test_text[\"TextEmbed\"],\n",
        "            Labels=test_text[\"Labels\"]\n",
        "        )\n",
        "\n",
        "    #--------------------------------------------------------------------------\n",
        "    # 5) Merge classical + deep => \"image-based\" features\n",
        "    #--------------------------------------------------------------------------\n",
        "    print(\"[INFO] Merging classical + deep => 'image-based' features ...\")\n",
        "    X_train_img, y_train_img, X_train_classical, y_train_classical, X_train_deep, y_train_deep = merge_classical_and_deep_feats(train_classical, train_deep)\n",
        "    X_val_img,   y_val_img,X_val_classical, y_val_classical, X_val_deep, y_val_deep  = merge_classical_and_deep_feats(val_classical,   val_deep)\n",
        "    X_test_img,  y_test_img,X_test_classical, y_test_classical, X_test_deep, y_test_deep  = merge_classical_and_deep_feats(test_classical,  test_deep)\n",
        "    print(f\"Image-based dims => train= {X_train_img.shape}, val= {X_val_img.shape}, test= {X_test_img.shape}\")\n",
        "\n",
        "    # Also keep text-based\n",
        "    X_train_text = train_text[\"TextEmbed\"]  # (N, 768)\n",
        "    y_train_text = train_text[\"Labels\"]\n",
        "    X_val_text   = val_text[\"TextEmbed\"]\n",
        "    y_val_text   = val_text[\"Labels\"]\n",
        "    X_test_text  = test_text[\"TextEmbed\"]\n",
        "    y_test_text  = test_text[\"Labels\"]\n",
        "\n",
        "    #--------------------------------------------------------------------------\n",
        "    # 6) Merge image + text => single big vector\n",
        "    #--------------------------------------------------------------------------\n",
        "    print(\"[INFO] Merging image+text features ...\")\n",
        "    X_train_all = np.hstack((X_train_img, X_train_text))\n",
        "    X_val_all   = np.hstack((X_val_img,   X_val_text))\n",
        "    X_test_all  = np.hstack((X_test_img,  X_test_text))\n",
        "\n",
        "    y_train_all = y_train_img\n",
        "    y_val_all   = y_val_img\n",
        "    y_test_all  = y_test_img\n",
        "\n",
        "    print(f\"Final Merged shapes => Train= {X_train_all.shape}, Val= {X_val_all.shape}, Test= {X_test_all.shape}\")\n",
        "\n",
        "    run_all_evaluations(X_train_img,y_train_img,X_val_img,y_val_img,X_test_img,y_test_img) #deep+classical image\n",
        "    print(\"OVER\")\n",
        "    run_all_evaluations(X_train_text,y_train_text,X_val_text,y_val_text,X_test_text,y_test_text) #text only\n",
        "    print(\"OVER\")\n",
        "    run_all_evaluations(X_train_classical,y_train_classical,X_val_classical,y_val_classical,X_test_classical,y_test_classical) #only classical\n",
        "    print(\"OVER\")\n",
        "    run_all_evaluations(X_train_deep,y_train_deep,X_val_deep,y_val_deep,X_test_deep,y_test_deep) #only deep\n",
        "    print(\"OVER\")\n",
        "    run_all_evaluations(X_train_all,y_train_all,X_val_all,y_val_all,X_test_all,y_test_all) #all\n",
        "    print(\"\\n[INFO] Done! End of pipeline.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main_pipeline()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
